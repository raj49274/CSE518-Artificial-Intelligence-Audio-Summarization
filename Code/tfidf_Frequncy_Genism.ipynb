{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfidf_Frequncy_Genism.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcQcB2rv0hh9"
      },
      "source": [
        "# Module Imports\n",
        "import re\n",
        "import webvtt\n",
        "from gensim.summarization.summarizer import summarize as gensim_based\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from tkinter import *\n",
        "from tkinter import filedialog\n",
        "import tkinter.font as tkFont\n",
        "import os\n",
        "import youtube_dl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "nlp =  spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOF-0sxW0hm_"
      },
      "source": [
        "# Function Block\n",
        "\n",
        "def get_caption(url):\n",
        "    global video_title\n",
        "    # Using Youtube-dl inside python\n",
        "    ydl_opts = {\n",
        "        'skip_download': True,        # Skipping the download of actual file\n",
        "        'writesubtitles': True,       # Uploaded Subtitles\n",
        "        \"writeautomaticsub\": True,    # Auto generated Subtitles\n",
        "        \"subtitleslangs\": ['en'],     # Language Needed \"en\"-->English\n",
        "        'outtmpl': 'test.%(ext)s',    # Saving downloaded file as 'test.en.vtt'\n",
        "        'nooverwrites': False,        # Overwrite if the file exists\n",
        "        'quiet': True                # Printing progress\n",
        "    }\n",
        "\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "        try:\n",
        "            ydl.download([url])\n",
        "            info_dict = ydl.extract_info(url, download=False)\n",
        "            video_title = info_dict.get('title', None)\n",
        "        except:\n",
        "            print(\"Try with a YouTube URL\")\n",
        "    corpus = []\n",
        "    for caption in webvtt.read('test.en.vtt'):\n",
        "        corpus.append(caption.text)\n",
        "    corpus = \"\".join(corpus)\n",
        "    corpus = corpus.replace('\\n', ' ')\n",
        "\n",
        "    return corpus\n",
        "\n",
        "\n",
        "def summarizer(text, option, fraction):\n",
        "    # \"Tf-IDF-Based\", \"Frequency-Based\", \"Gensim-Based\"\n",
        "    \n",
        "    frac=fraction\n",
        "    if option == \"TfIdf-Based\":\n",
        "        return tfidf_based(text, frac)\n",
        "    if option == \"Frequency-Based\":\n",
        "        return freq_based(text, frac)\n",
        "    if option == \"Gensim-Based\":\n",
        "        doc=nlp(text)\n",
        "        text=\"\\n\".join([sent.text for sent in doc.sents])\n",
        "        return gensim_based(text=text, ratio=frac)\n",
        "\n",
        "def tfidf_based(msg,fraction=0.3):\n",
        "    # Creating Pipeline\n",
        "    doc=nlp(msg)\n",
        "    \n",
        "    #Sent_tokenize\n",
        "    sents =[sent.text for sent in doc.sents]\n",
        "    \n",
        "    #Number of Sentence User wants\n",
        "    num_sent=int(np.ceil(len(sents)*fraction))\n",
        "    \n",
        "    #Creating tf-idf removing the stop words matching token pattern of only text\n",
        "    tfidf=TfidfVectorizer(stop_words='english',token_pattern='(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
        "    X=tfidf.fit_transform(sents)\n",
        "    \n",
        "    #Creating a df with data and tf-idf value\n",
        "    df=pd.DataFrame(data=X.todense(),columns=tfidf.get_feature_names())\n",
        "    indexlist=list(df.sum(axis=1).sort_values(ascending=False).index)\n",
        "#     indexlist=list((df.sum(axis=1)/df[df>0].count(axis=1)).sort_values(ascending=False).index)\n",
        "    \n",
        "    # Subsetting only user needed sentence\n",
        "    needed = indexlist[:num_sent]\n",
        "    \n",
        "    #Sorting the document in order\n",
        "    needed.sort()\n",
        "    \n",
        "    #Appending summary to a list--> convert to string --> return to user\n",
        "    summary=[]\n",
        "    for i in needed:\n",
        "        summary.append(sents[i])\n",
        "    summary=\"\".join(summary)\n",
        "    summary = summary.replace(\"\\n\",'')\n",
        "    return summary\n",
        "\n",
        "\n",
        "def freq_based(text, fraction):\n",
        "    # Convert to pipeline\n",
        "    doc = nlp(text)\n",
        "    # Break to sentences\n",
        "    sentence = [sent for sent in doc.sents]\n",
        "    # Number of sentence user wants\n",
        "    numsentence = int(np.ceil(fraction*len(sentence)))\n",
        "\n",
        "    # Tokenizing and filtering key words\n",
        "    words = [word.text.lower()\n",
        "             for word in doc.doc if word.is_alpha and word.is_stop == False]\n",
        "    # Converting to df for calculating weighted frequency\n",
        "    df = pd.DataFrame.from_dict(\n",
        "        data=dict(Counter(words)), orient=\"index\", columns=[\"freq\"])\n",
        "    df[\"wfreq\"] = np.round(df.freq/df.freq.max(), 3)\n",
        "    df = df.drop('freq', axis=1)\n",
        "\n",
        "    # Convert weighted frequency back to dict\n",
        "    wfreq_words = df.wfreq.to_dict()\n",
        "\n",
        "    # Weight each sentence based on their wfreq\n",
        "    sent_weight = []\n",
        "    for sent in sentence:\n",
        "        temp = 0\n",
        "        for word in sent:\n",
        "            if word.text.lower() in wfreq_words:\n",
        "                temp += wfreq_words[word.text.lower()]\n",
        "        sent_weight.append(temp)\n",
        "    wdf = pd.DataFrame(data=np.round(sent_weight, 3), columns=['weight'])\n",
        "    wdf = wdf.sort_values(by='weight', ascending=False)\n",
        "    indexlist = list(wdf.iloc[:numsentence, :].index)\n",
        "\n",
        "    # Summary\n",
        "    sumlist = []\n",
        "    for s in indexlist[:5]:\n",
        "        sumlist.append(sentence[s])\n",
        "    summary = ''.join(token.string.strip() for token in sumlist)\n",
        "    return summary"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL7f8ZjS2M-s"
      },
      "source": [
        "text = get_caption(\"https://www.youtube.com/watch?v=jtpOYxsZj7o\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "id": "s6zyvFnT4mQF",
        "outputId": "83c661dc-7def-47cf-b7e3-0ce251d6a493"
      },
      "source": [
        "text"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"  look human beings we can't helplook human beings we can't help  look human beings we can't help ourselves but compare ourselves toourselves but compare ourselves to  ourselves but compare ourselves to others andothers and  others and comparison is is the deadliest thing wecomparison is is the deadliest thing we  comparison is is the deadliest thing we can do to ourselves because we willcan do to ourselves because we will  can do to ourselves because we will always come up short i mean it'll all italways come up short i mean it'll all it  always come up short i mean it'll all it does is exaggerate all of ourdoes is exaggerate all of our  does is exaggerate all of our insecuritiesinsecurities  insecurities it's okay to enjoy other people'sit's okay to enjoy other people's  it's okay to enjoy other people's success but you let them live theirsuccess but you let them live their  success but you let them live their lives and you live your life oh and bylives and you live your life oh and by  lives and you live your life oh and by the way they're curating their socialthe way they're curating their social  the way they're curating their social media that's not really their lifemedia that's not really their life  media that's not really their life um and so you're making decisions basedum and so you're making decisions based  um and so you're making decisions based on how you feel based on their curatedon how you feel based on their curated  on how you feel based on their curated things i know i've talked to so manythings i know i've talked to so many  things i know i've talked to so many millennials i know somebody who's out ofmillennials i know somebody who's out of  millennials i know somebody who's out of work really depressed and yet she goeswork really depressed and yet she goes  work really depressed and yet she goes and does all these things so she has theand does all these things so she has the  and does all these things so she has the appearance of this amazing successfulappearance of this amazing successful  appearance of this amazing successful lifelife  life and and so you met now she may be makingand and so you met now she may be making  and and so you met now she may be making those decisions based on what herthose decisions based on what her  those decisions based on what her friends oh who knows what sort of weirdfriends oh who knows what sort of weird  friends oh who knows what sort of weird twisted exaggerated you know circle oftwisted exaggerated you know circle of  twisted exaggerated you know circle of of of depression this is formingof of depression this is forming  of of depression this is forming so go back to the rules of the infiniteso go back to the rules of the infinite  so go back to the rules of the infinite game your friends are there to admiregame your friends are there to admire  game your friends are there to admire your friends are there to say god thatyour friends are there to say god that  your friends are there to say god that i'm so happy for them what are theyi'm so happy for them what are they  i'm so happy for them what are they doing that i can learn from i'll givedoing that i can learn from i'll give  doing that i can learn from i'll give you an example soyou an example so  you an example so we're all so we can all fall into thiswe're all so we can all fall into this  we're all so we can all fall into this trap so you know in my businesstrap so you know in my business  trap so you know in my business uhuh  uh authors and speakers and folks like usauthors and speakers and folks like us  authors and speakers and folks like us we're all comparing ourselves to eachwe're all comparing ourselves to each  we're all comparing ourselves to each other and sometimes it can get silly andother and sometimes it can get silly and  other and sometimes it can get silly and competitive and there was you knowcompetitive and there was you know  competitive and there was you know sometimes i go on amazon and check thesometimes i go on amazon and check the  sometimes i go on amazon and check the rankings of my books to see that there'srankings of my books to see that there's  rankings of my books to see that there's that i still have a jobthat i still have a job  that i still have a job and and now and then there was this oneand and now and then there was this one  and and now and then there was this one authorauthor  author who i hated for no reasonwho i hated for no reason  who i hated for no reason he's very smart his work's incrediblyhe's very smart his work's incredibly  he's very smart his work's incredibly good he's incredibly well respected igood he's incredibly well respected i  good he's incredibly well respected i respect him but i hate himrespect him but i hate him  respect him but i hate him and i would check the rankings of hisand i would check the rankings of his  and i would check the rankings of his booksbooks  books and when i was ahead i'd be like yesand when i was ahead i'd be like yes  and when i was ahead i'd be like yes and when he was ahead of likeand when he was ahead of like  and when he was ahead of like right it would drive me crazy i had thisright it would drive me crazy i had this  right it would drive me crazy i had this weird abstract competitionweird abstract competition  weird abstract competition same thing right social media happenedsame thing right social media happened  same thing right social media happened to be amazon rankings rightto be amazon rankings right  to be amazon rankings right and i would check in all the time i'dand i would check in all the time i'd  and i would check in all the time i'd always check in mine his mind his nobodyalways check in mine his mind his nobody  always check in mine his mind his nobody else just mine and hiselse just mine and his  else just mine and his anyway we were uh i was at an event andanyway we were uh i was at an event and  anyway we were uh i was at an event and we were interviewed together on the samewe were interviewed together on the same  we were interviewed together on the same stagestage  stage and the interviewer decided to let us inand the interviewer decided to let us in  and the interviewer decided to let us in introduce each otherintroduce each other  introduce each other so i went first i had to introduce himso i went first i had to introduce him  so i went first i had to introduce him and this is what i said i looked at himand this is what i said i looked at him  and this is what i said i looked at him and i said uh you make me very insecure     i said uh because all of your strengthsi said uh because all of your strengths  i said uh because all of your strengths are all of my weaknessesare all of my weaknesses  are all of my weaknesses and every time i see you do well it justand every time i see you do well it just  and every time i see you do well it just reminds me what i'm bad atreminds me what i'm bad at  reminds me what i'm bad at that's how i opened upthat's how i opened up  that's how i opened up hehe  he he turned to me and he said funny i feelhe turned to me and he said funny i feel  he turned to me and he said funny i feel the same way about you     and now we love each otherand now we love each other  and now we love each other because i realizedbecause i realized  because i realized thatthat  that he's really good at what i'm bad at sohe's really good at what i'm bad at so  he's really good at what i'm bad at so by me getting to know him and reallyby me getting to know him and really  by me getting to know him and really learning to love him i'm realizing i'mlearning to love him i'm realizing i'm  learning to love him i'm realizing i'm getting better at those thingsgetting better at those things  getting better at those things and i'm taking more pride in the thingsand i'm taking more pride in the things  and i'm taking more pride in the things that i'm good at rather thinking ratherthat i'm good at rather thinking rather  that i'm good at rather thinking rather than thinking i have to be good atthan thinking i have to be good at  than thinking i have to be good at everything he's good ateverything he's good at  everything he's good at right so that that it's it's healthy toright so that that it's it's healthy to  right so that that it's it's healthy to grow our own strengths and rather thangrow our own strengths and rather than  grow our own strengths and rather than be intimidated by the strengths ofbe intimidated by the strengths of  be intimidated by the strengths of others\""
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "Vbb7p_p82wTF",
        "outputId": "ad927c55-f860-4410-ae18-fd557bc23891"
      },
      "source": [
        "summarizer(text, \"Gensim-Based\", 0.2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"look human beings\\nwe can't help  look human beings\\ni mean it'll all italways come up short\\nbut you let them live theirsuccess\\nbut you let them live their  success\\nand you live your life\\nand you live your life\\nand you live your life\\nand so you're making decisions based  \\nand so you're making decisions based on how you feel based on their curatedon how you feel based on their curated  on how you feel based on their curated things\\ni know i've talked to so many  things\\ni know i've talked to so many millennials\\ni know somebody who's out of  millennials\\ni know somebody who's out of work really depressed and\\noh who knows what sort of weird  \\noh who knows what sort of weird twisted exaggerated\\ntwisted exaggerated you know\\nthis is forming so go back to the rules of the infiniteso\\nso go back to the rules of the infinite game your friends are there to admiregame your friends\\nso you know in my business  trap\\nyou know  competitive\\nyou know sometimes i go on amazon and check thesometimes\\nhis work's incredibly good\\nand when i was ahead i'd be like yes\\nright it would drive me crazy\\nand i would check in all the time\\nand this is what i said i looked at himand\\nand this is what i said i looked at him\\nand this is what i said i looked at him\\ni'm realizing i'mlearning to love him\\ni'm  learning to love him\\ni'm taking more pride in the things  \\nand i'm taking more pride in the things that i'm good at rather thinking\\nhe's good at right\""
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAL_44fG4eYu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}